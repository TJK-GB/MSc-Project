{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dc4f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "BASE_PATH = r\"C:\\Users\\a9188\\Documents\\00. 2024 QMUL\\00. Course\\Project\\00. ACTUAL\"\n",
    "ANNOTATION_DIR = os.path.join(BASE_PATH, \"annotations\", \"Original\")\n",
    "\n",
    "FRAME_ANNOTATION_PATH = os.path.join(ANNOTATION_DIR, \"annotation_(framelevel_refinement).xlsx\")\n",
    "SOUND_ANNOTATION_PATH = os.path.join(ANNOTATION_DIR, \"annotation(sound_time unit)_ver2.xlsx\")\n",
    "\n",
    "file_1 = pd.read_excel(FRAME_ANNOTATION_PATH)\n",
    "file_2 = pd.read_excel(SOUND_ANNOTATION_PATH)\n",
    "video_df = pd.DataFrame(file_1)\n",
    "sound_df = pd.DataFrame(file_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfee71b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_df = sound_df.rename(columns={\n",
    "    'Start frame' : 'Start frame(sound)',\n",
    "    'End frame' : 'End frame(sound)',\n",
    "    'Sound Type' : 'sound_label'\n",
    "    })\n",
    "\n",
    "video_df = video_df.rename(columns={\n",
    "    'Start Frame' : 'Start frame',\n",
    "    'End Frame' : 'End frame',\n",
    "    'Violence Type (Sound)' : 'Violence(Sound) Type',\n",
    "    'Start Time (s)' : 'Start time(s)',\n",
    "    'End Time (s)' : 'End time(s)'\n",
    "})\n",
    "\n",
    "sound_df_refined = sound_df.drop(columns =[\n",
    "                                 'Filename',\n",
    "                                 'Duplicated moment with previous',\n",
    "                                 'Sound Start',\n",
    "                                 'Sound End',\n",
    "                                 'Max frame',\n",
    "                                 'Max Time'])\n",
    "\n",
    "video_df_refined = video_df.astype(\n",
    "    {'Video ID': int,\n",
    "     'Start frame':float,\n",
    "     'End frame':float}\n",
    "     )\n",
    "\n",
    "sound_df_refined = sound_df_refined.astype(\n",
    "    {'Video ID':int,\n",
    "     'Start frame(sound)':float,\n",
    "     'End frame(sound)':float}\n",
    "     )\n",
    "\n",
    "combined_df = video_df_refined.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b98edbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. match the 'Video ID' column in both dataframes\n",
    "# 2. if  they match, \n",
    "#    - append the 'sound_start_frame' and 'sound_end_frame' from sound_df_refined to video_df_refined\n",
    "#    - append the 'sound_label' from sound_df_refined to video_df_refined as 'Violence(Sound) Type'\n",
    "\n",
    "# 3. if there are more than one 'sound_start_frame' and 'sound_end_frame' for the same 'Video ID', \n",
    "#    - append them as separate columns in video_df_refined\n",
    "#    - the columns should be soundtype{i}, startframe{i}, endframe{i}, soundtype2, etc. for the sound labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e166442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Video ID', 'Filename', 'Start frame', 'End frame', 'Start time(s)',\n",
       "       'End time(s)', 'Violence Type (Video)', 'Video Type',\n",
       "       'Violence Type (Text)', 'Manual Text', 'Memo'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a0097c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Video ID', 'Title', 'Violence(Sound) Type', 'Start time(s)',\n",
       "       'End time(s)', 'Start frame(sound)', 'End frame(sound)', 'sound_label',\n",
       "       'Memos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sound_df_refined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb89065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Stage\n",
    "    if s_video_id from sound_df_refined match with video_df_refined:\n",
    "then 1) check Start frame in combined_df and then\n",
    "\n",
    "# Second Stage\n",
    "2) if sound_df_refined 'sound_start_frame' is bigger than combined_df and smaller then 'End frame' in combined_df, \n",
    "- 'Violence(Sound) Type' in sound_df_refined value goes to the column called 'Violence(sound) type{i}}' if this column cell is empty.\n",
    "- 'Sound label' in sound_df_refined value goes to the column called 'Sound type{i}}' if this column cell is empty\n",
    "- 'Start frame(sound)' in sound_df_refined value goes to the column called 'sound_start_frame{i}' if this column cell is empty\n",
    "- 'End frame(sound)' in sound_df_refined value goes to the column called 'sound_end_frame{i}' if this column cell is empty\n",
    "\n",
    "if the cells are all filled already, then next number of the Violence(Sound) Type{i}, Sound type{i}, sound_start_frame, sound_end_frame will be filled.FileLink\n",
    "\n",
    "# Third Stage\n",
    "3) if inserted cell that has bigger End frame(sound) in sound_df_refined than the stated End frame in combined_df, then whatever the max number between End frame(sound)(in sound_df_refined) or 'End frame' in combined_df is goes to the sound_end frame(this is to see if the range go over the End frame stated in the combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a753c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_columns = 11\n",
    "for i in range(1, max_columns + 1):\n",
    "    combined_df[f'Violence(Sound) Type{i}'] = None\n",
    "    combined_df[f'Sound type{i}'] = None\n",
    "    combined_df[f'sound_start_frame{i}'] = None\n",
    "    combined_df[f'sound_end_frame{i}'] = None\n",
    "\n",
    "combined_df.sort_values(by=['Video ID', 'Start frame'], inplace=True)\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for sound_idx, sound_row in sound_df_refined.iterrows():\n",
    "    s_video_id = sound_row['Video ID']\n",
    "    s_type = sound_row['Violence(Sound) Type']\n",
    "    s_start = sound_row['Start frame(sound)']\n",
    "    s_end = sound_row['End frame(sound)']\n",
    "    s_label = sound_row['sound_label']\n",
    "\n",
    "    matches = combined_df[\n",
    "        (combined_df['Video ID'] == s_video_id) &\n",
    "        (combined_df['Start frame'] <= s_start) &\n",
    "        (combined_df['End frame'] >= s_start)\n",
    "    ]\n",
    "\n",
    "    if matches.empty:\n",
    "        continue\n",
    "\n",
    "    for match_idx in matches.index:\n",
    "        for ix in range(1, max_columns + 1):\n",
    "            if pd.isna(combined_df.at[match_idx, f'Violence(Sound) Type{ix}']):\n",
    "                combined_df.at[match_idx, f'Violence(Sound) Type{ix}'] = s_type\n",
    "                combined_df.at[match_idx, f'Sound type{ix}'] = s_label\n",
    "                combined_df.at[match_idx, f'sound_start_frame{ix}'] = s_start\n",
    "                fill_end = min(s_end, combined_df.at[match_idx, 'End frame'])\n",
    "                combined_df.at[match_idx, f'sound_end_frame{ix}'] = fill_end\n",
    "                break\n",
    "\n",
    "        if s_end > combined_df.at[match_idx, 'End frame']:\n",
    "            remaining_start = combined_df.at[match_idx, 'End frame'] + 1\n",
    "\n",
    "            while remaining_start <= s_end:\n",
    "                next_matches = combined_df[\n",
    "                    (combined_df['Video ID'] == s_video_id) &\n",
    "                    (combined_df['Start frame'] <= remaining_start) &\n",
    "                    (combined_df['End frame'] >= remaining_start)\n",
    "                ]\n",
    "\n",
    "                if next_matches.empty:\n",
    "                    break\n",
    "\n",
    "                for next_idx in next_matches.index:\n",
    "                    segment_end = combined_df.at[next_idx, 'End frame']\n",
    "\n",
    "                    for next_ix in range(1, max_columns + 1):\n",
    "                        if pd.isna(combined_df.at[next_idx, f'Violence(Sound) Type{next_ix}']):\n",
    "                            combined_df.at[next_idx, f'Violence(Sound) Type{next_ix}'] = s_type\n",
    "                            combined_df.at[next_idx, f'Sound type{next_ix}'] = s_label\n",
    "                            combined_df.at[next_idx, f'sound_start_frame{next_ix}'] = remaining_start\n",
    "                            combined_df.at[next_idx, f'sound_end_frame{next_ix}'] = min(s_end, segment_end)\n",
    "                            remaining_start = segment_end + 1\n",
    "                            break\n",
    "                    break  # always move to next row after a fill\n",
    "        break  # only one initial match per sound_row\n",
    "\n",
    "output_path = os.path.join(BASE_PATH, \"annotations\", \"combined_sound_frame_annotations.xlsx\")\n",
    "combined_df.to_excel(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
